# import streamlit as st
# import numpy as np
# import pandas as pd
# import plotly.express as px

# from connect3.env import Connect3Env
# from connect3.agent import QLearningAgent
# from connect3.train import TrainConfig, train_q_agent, evaluate
# from connect3.opponents import random_opponent, heuristic_opponent
# from connect3.utils import board_to_emoji

# import time

# st.set_page_config(page_title="Connect-3 RL (4x4)", layout="wide")
# st.title("ðŸŽ® 4Ã—4 Connect-3 â€” Q-Learning Agent")
# st.caption("A simplified reinforcement learning project: tabular Q-learning + Îµ-greedy exploration + interactive demo.")

# # -----------------------
# # Session state
# # -----------------------
# if "pending_agent" not in st.session_state:
#     st.session_state.pending_agent = False
# if "pending_state_index" not in st.session_state:
#     st.session_state.pending_state_index = None
# if "trained_agent" not in st.session_state:
#     st.session_state.trained_agent = None
# if "train_df" not in st.session_state:
#     st.session_state.train_df = None
# if "play_env" not in st.session_state:
#     st.session_state.play_env = Connect3Env(step_penalty=0.0)
#     st.session_state.play_env.reset()
# if "play_done" not in st.session_state:
#     st.session_state.play_done = False
# if "play_message" not in st.session_state:
#     st.session_state.play_message = ""
# if "human_starts" not in st.session_state:
#     st.session_state.human_starts = True


# tab_train, tab_play = st.tabs(["Train", "Play"])

# with tab_train:
#     left, right = st.columns([1, 2])

#     with left:
#         st.subheader("Training controls")

#         episodes = st.slider("Episodes", 1000, 50000, 12000, step=1000)
#         opponent = st.selectbox("Opponent", ["random", "heuristic"], index=0)
#         alpha = st.slider("Learning rate (Î±)", 0.05, 0.8, 0.2, step=0.05)
#         gamma = st.slider("Discount (Î³)", 0.5, 0.99, 0.95, step=0.01)
#         eps_start = st.slider("Îµ start", 0.05, 0.9, 0.4, step=0.05)
#         eps_end = st.slider("Îµ end", 0.0, 0.2, 0.05, step=0.01)
#         eps_decay_frac = st.slider("Îµ decay fraction", 0.2, 1.0, 0.7, step=0.05)
#         step_penalty = st.select_slider("Step penalty (optional)", options=[0.0, -0.005, -0.01, -0.02], value=0.0)

#         train_btn = st.button("Train", type="primary")

#     with right:
#         st.subheader("Results")

#         if train_btn:
#             cfg = TrainConfig(
#                 episodes=episodes,
#                 opponent=opponent,
#                 alpha=alpha,
#                 gamma=gamma,
#                 epsilon_start=eps_start,
#                 epsilon_end=eps_end,
#                 epsilon_decay_frac=eps_decay_frac,
#                 step_penalty=step_penalty,
#                 seed=42,
#             )
#             with st.spinner("Training..."):
#                 agent, df = train_q_agent(cfg)

#             st.session_state.trained_agent = agent
#             st.session_state.train_df = df

#         if st.session_state.train_df is None:
#             st.info("Train an agent to see learning curves and evaluation results.")
#         else:
#             df = st.session_state.train_df

#             c1, c2, c3 = st.columns(3)
#             c1.metric("Episodes", f"{int(df['episode'].iloc[-1]):,}")
#             c2.metric("Final Îµ", f"{df['epsilon'].iloc[-1]:.3f}")
#             c3.metric("Win rate (last 200)", f"{df['win_rate_200'].iloc[-1]:.3f}")

#             fig = px.line(
#                 df,
#                 x="episode",
#                 y=["win_rate_200", "loss_rate_200", "draw_rate_200"],
#                 title="Moving outcome rates (window=200)",
#             )
#             st.plotly_chart(fig, use_container_width=True)
#             agent = st.session_state.trained_agent
#             eval_random = evaluate(agent, episodes=2000, opponent="random", seed=1)
#             eval_heur = evaluate(agent, episodes=2000, opponent="heuristic", seed=2)

#             st.markdown("### Evaluation (greedy policy)")
#             st.write(pd.DataFrame([{
#                 "Opponent": "random",
#                 "Win rate": eval_random["win_rate"],
#                 "Loss rate": eval_random["loss_rate"],
#                 "Draw rate": eval_random["draw_rate"],
#             },{
#                 "Opponent": "heuristic",
#                 "Win rate": eval_heur["win_rate"],
#                 "Loss rate": eval_heur["loss_rate"],
#                 "Draw rate": eval_heur["draw_rate"],
#             }]))

# # -----------------------
# # PLAY TAB
# # -----------------------
# with tab_play:
#     st.subheader("Play against the trained agent")

#     if st.session_state.trained_agent is None:
#         st.warning("Train an agent first in the **Train** tab.")
#     else:
#         env: Connect3Env = st.session_state.play_env
#         agent: QLearningAgent = st.session_state.trained_agent
#         rng = np.random.default_rng(123)

#         top = st.columns([1, 1, 2])
#         with top[0]:
#             if st.button("Reset game"):
#                 env.reset()
#                 st.session_state.play_done = False
#                 st.session_state.play_message = ""
#         with top[1]:
#             st.session_state.human_starts = st.toggle("Human starts", value=st.session_state.human_starts)

    
#         if (not st.session_state.human_starts) and (not st.session_state.play_done) and np.all(env.board == 0):
#             s = env.get_state()
#             a = agent.act(s, env.valid_actions(), rng=rng, greedy=True)
#             env.drop(a, player=+1)

#         st.markdown("#### Board")
#         st.code(board_to_emoji(env.board))

#         # Column buttons for human move
#         cols = st.columns(env.COLS)
#         human_move = None
#         for c in range(env.COLS):
#             with cols[c]:
#                 if st.button(f"Drop in {c}", disabled=st.session_state.play_done or (env.board[0, c] != 0)):
#                     human_move = c

#         def finalize_if_terminal(env):
#             w = env.check_winner()
#             if w != 0:
#                 st.session_state.play_done = True
#                 st.session_state.play_message = "You win! ðŸŸ¡" if w == -1 else "Agent wins! ðŸ”´"
#                 return True
#             if env.is_full():
#                 st.session_state.play_done = True
#                 st.session_state.play_message = "Draw."
#                 return True
#             return False


#         import plotly.graph_objects as go
#         import numpy as np


#         if st.session_state.pending_agent and (not st.session_state.play_done):
#             st.markdown("### Agent turn")


#             s = env.get_state()
#             valid = env.valid_actions()

#             all_actions = list(range(env.COLS))
#             q_list = []
#             for a in all_actions:
#                 if a in valid:
#                     q_list.append(agent.get_q(s, a))
#                 else:
#                     q_list.append(None) 
#             finite = [v for v in q_list if isinstance(v, (int, float))]
#             max_abs = float(np.max(np.abs(finite))) if finite else 0.0
#             ypad = max(0.5, max_abs * 1.2)  # ensures non-flat axis



#             with st.spinner("Agent thinking..."):
#                 time.sleep(0.4)

#                 a = agent.act(s, valid, rng=rng, greedy=True)
#                 env.drop(a, player=+1)

#             st.session_state.pending_agent = False
#             finalize_if_terminal(env)
#             st.rerun()


#         # --- Human plays---
#         if human_move is not None and (not st.session_state.play_done) and (not st.session_state.pending_agent):
#             ok = env.drop(human_move, player=-1)
#             if not ok:
#                 st.session_state.play_message = "Invalid move (column full)."
#                 st.rerun()
#             else:
#                 if not finalize_if_terminal(env):
#                     st.session_state.pending_agent = True
#                 st.rerun()

#         if st.session_state.play_message:
#             st.success(st.session_state.play_message)



import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px

st.set_page_config(page_title="Connect-3 RL (4x4)", layout="wide")
st.title("ðŸŽ® 4Ã—4 Connect-3 â€” Q-Learning Agent")
st.caption(
    "A simplified reinforcement learning project: tabular Q-learning + Îµ-greedy exploration + interactive demo."
)

# Tabs
tab_train, tab_play = st.tabs(["Train", "Play"])

# -----------------------
# TRAIN TAB (UI only)
# -----------------------
with tab_train:
    left, right = st.columns([1, 2])

    with left:
        st.subheader("Training controls")

        episodes = st.slider("Episodes", 1000, 50000, 12000, step=1000)
        opponent = st.selectbox("Opponent", ["random", "heuristic"], index=0)
        alpha = st.slider("Learning rate (Î±)", 0.05, 0.8, 0.2, step=0.05)
        gamma = st.slider("Discount (Î³)", 0.5, 0.99, 0.95, step=0.01)
        eps_start = st.slider("Îµ start", 0.05, 0.9, 0.4, step=0.05)
        eps_end = st.slider("Îµ end", 0.0, 0.2, 0.05, step=0.01)
        eps_decay_frac = st.slider("Îµ decay fraction", 0.2, 1.0, 0.7, step=0.05)
        step_penalty = st.select_slider(
            "Step penalty (optional)",
            options=[0.0, -0.005, -0.01, -0.02],
            value=0.0,
        )

        train_btn = st.button("Train", type="primary")

    with right:
        st.subheader("Results")

        # Metrics placeholders
        c1, c2, c3 = st.columns(3)
        c1.metric("Episodes", "12,000")
        c2.metric("Final Îµ", "0.052")
        c3.metric("Win rate (last 200)", "0.63")

        # Fake training curve
        episodes_range = np.arange(0, 2000, 50)
        df_fake = pd.DataFrame({
            "episode": episodes_range,
            "win_rate_200": np.clip(np.linspace(0.2, 0.75, len(episodes_range)) + np.random.normal(0, 0.03, len(episodes_range)), 0, 1),
            "loss_rate_200": np.clip(np.linspace(0.6, 0.2, len(episodes_range)) + np.random.normal(0, 0.03, len(episodes_range)), 0, 1),
            "draw_rate_200": np.clip(np.linspace(0.2, 0.05, len(episodes_range)), 0, 1),
        })

        fig = px.line(
            df_fake,
            x="episode",
            y=["win_rate_200", "loss_rate_200", "draw_rate_200"],
            title="Example learning curve (placeholder)",
        )
        st.plotly_chart(fig, use_container_width=True)

        # Fake evaluation table
        st.markdown("### Evaluation (greedy policy)")
        eval_df = pd.DataFrame([
            {"Opponent": "random", "Win rate": 0.78, "Loss rate": 0.12, "Draw rate": 0.10},
            {"Opponent": "heuristic", "Win rate": 0.54, "Loss rate": 0.30, "Draw rate": 0.16},
        ])
        st.dataframe(eval_df, use_container_width=True)


# -----------------------
# PLAY TAB (UI only)
# -----------------------
with tab_play:
    st.subheader("Play against the trained agent")

    top = st.columns([1, 1, 2])
    with top[0]:
        st.button("Reset game")
    with top[1]:
        st.toggle("Human starts", value=True)

    st.markdown("#### Board")

    # Example board placeholder
    example_board = ""
    st.code(example_board)

    st.markdown("### Make a move")
    cols = st.columns(4)
    for c in range(4):
        with cols[c]:
            st.button(f"Drop in {c}")

    # Example status message